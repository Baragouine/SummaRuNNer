{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "606fa719",
   "metadata": {},
   "source": [
    "# Train RNN_RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a5bd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.GloveMgr import GloveMgr\n",
    "from utils.Dataset import Dataset\n",
    "from utils.DataLoader import DataLoader\n",
    "from utils.preprocess_df import preprocess_df\n",
    "from utils.accuracy_nb_sent_per_doc import accuracy_nb_sent_per_doc_fn\n",
    "from utils.accuracy_prop_sent_per_doc import accuracy_prop_sent_per_doc_fn\n",
    "\n",
    "#from models.RNN_RNN import RNN_RNN\n",
    "\n",
    "from time import time\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "824eacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 150000\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "learning_rate = 1e-3\n",
    "model_name = \"RNN_RNN\"\n",
    "average_proportion_of_sentences_per_document = 0.2670278281534701\n",
    "average_number_of_sentences_per_document = 6.061850780738518"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09bc3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of available GPUs: 1\n",
      "GPU 0: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "if torch.cuda.is_available():\n",
    "    # Display the number of available GPUs\n",
    "    print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
    "    # Display the name of each GPU\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"No GPU available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c5786e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  dev = \"cuda:0\" \n",
    "else:  \n",
    "  dev = \"cpu\" \n",
    "\n",
    "device = torch.device(dev)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97644745",
   "metadata": {},
   "outputs": [],
   "source": [
    "glovemgr = GloveMgr(\"./data/glove.6B/glove.6B.100d.txt\", vocab_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe745c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(preprocess_df(pd.read_json(\"./data/train.json\"), glovemgr=glovemgr, is_sep_n=True, remove_stop_word=True, stemming=False, trunc_sent=50, padding_sent=50, trunc_doc=100))\n",
    "train_iter = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8b39f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(preprocess_df(pd.read_json(\"./data/val.json\"), glovemgr=glovemgr, is_sep_n=True, remove_stop_word=True, stemming=False, trunc_sent=50, padding_sent=50, trunc_doc=100))\n",
    "val_iter = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d4a9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.BasicModel import BasicModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN_RNN(BasicModel):\n",
    "    def __init__(self, device, vocab_size, word_embed = None):\n",
    "        super(RNN_RNN, self).__init__(device)\n",
    "\n",
    "        self.device = device\n",
    "\n",
    "        self.word_embedding = nn.Embedding(vocab_size+2, 100, padding_idx=0)\n",
    "        # Load word embedding if specified\n",
    "        if word_embed is not None:\n",
    "            self.word_embedding = torch.nn.Embedding.from_pretrained(torch.from_numpy(word_embed).float())\n",
    "\n",
    "        # 100 : word2vec embedding size\n",
    "        self.word_GRU = nn.GRU(input_size = 100, hidden_size = 200, batch_first = True, bidirectional = True)\n",
    "        self.sent_GRU = nn.GRU(input_size = 2*200, hidden_size=200, batch_first = True, bidirectional = True)\n",
    "\n",
    "        # 10: relative position range size, with segment size = 10\n",
    "        self.rel_pos_emb = nn.Embedding(11, 100)\n",
    "        self.abs_pos_emb = nn.Embedding(100, 100)\n",
    "\n",
    "        self.Wdoc = nn.Linear(2*200,2*200,bias=True)\n",
    "\n",
    "        self.Wcontent = nn.Linear(2*200,1,bias=False)\n",
    "        self.Wsalience = nn.Bilinear(2*200,2*200,1,bias=False)\n",
    "        self.Wnovelty = nn.Bilinear(2*200,2*200,1,bias=False)\n",
    "        self.Wabs_pos = nn.Linear(100,1,bias=False)\n",
    "        self.Wrel_pos = nn.Linear(100,1,bias=False)\n",
    "        self.bias = nn.Parameter(torch.empty(1).uniform_(-0.1, 0.1))\n",
    "\n",
    "    def avg_pool1d(self,x,seq_lens):\n",
    "        out = []\n",
    "        for index,t in enumerate(x):\n",
    "            if seq_lens[index] == 0:\n",
    "                t = t[:1]\n",
    "            else:\n",
    "                t = t[:seq_lens[index],:]\n",
    "            t = torch.t(t).unsqueeze(0)\n",
    "            out.append(F.avg_pool1d(t,t.size(2)))\n",
    "        \n",
    "        out = torch.cat(out).squeeze(2)\n",
    "        return out\n",
    "\n",
    "    def forward(self, arr_x, doc_lens):\n",
    "        probs = []\n",
    "\n",
    "        sent_lens = torch.sum(torch.sign(arr_x),dim=1).data\n",
    "        arr_x = self.word_embedding(arr_x)\n",
    "        arr_x = self.word_GRU(arr_x)[0]\n",
    "        arr_x = self.avg_pool1d(arr_x, sent_lens)\n",
    "\n",
    "        arr_x = self.pad_doc(arr_x, doc_lens)\n",
    "\n",
    "        arr_x = self.sent_GRU(arr_x)[0]\n",
    "        docs = self.avg_pool1d(arr_x, doc_lens)\n",
    "\n",
    "        # for each document, compute probabilities\n",
    "        for idx, doc_len in enumerate(doc_lens):\n",
    "            sents = arr_x[idx,:doc_len,:]\n",
    "            d = torch.tanh(self.Wdoc(docs[idx])).unsqueeze(0)\n",
    "            s = torch.zeros(1,2*200)\n",
    "            s = s.to(self.device)\n",
    "            #prob_doc = []\n",
    "            for position, h in enumerate(sents):\n",
    "                h = h.view(1, -1) # resize\n",
    "                # Compute position embedding\n",
    "                abs_pos = torch.tensor([[position]], dtype=torch.long)\n",
    "                abs_pos = abs_pos.to(self.device)\n",
    "                abs_pos = self.abs_pos_emb(abs_pos).squeeze(0)\n",
    "\n",
    "                # Compute relative position embedding\n",
    "                rel_pos = int(round(position / 10))\n",
    "                rel_pos = torch.tensor([[rel_pos]], dtype=torch.long)\n",
    "                rel_pos = rel_pos.to(self.device)\n",
    "                rel_pos = self.rel_pos_emb(rel_pos).squeeze(0)\n",
    "\n",
    "                # Compute proba\n",
    "                content = self.Wcontent(h)\n",
    "                salience = self.Wsalience(h, d)\n",
    "                novelty = -1 * self.Wnovelty(h,torch.tanh(s))\n",
    "                ap = self.Wabs_pos(abs_pos)\n",
    "                rp = self.Wrel_pos(rel_pos)\n",
    "                prob = torch.sigmoid(content+salience+novelty+ap+rp+self.bias)\n",
    "\n",
    "                #prob_doc.append(prob)\n",
    "                probs.append(prob)\n",
    "\n",
    "                s = s + torch.mm(prob,h)\n",
    "\n",
    "            #probs.append(torch.tensor(prob_doc))\n",
    "\n",
    "        probs = torch.cat(probs).squeeze()\n",
    "        #probs = probs.to(self.device)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "380f8ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN_RNN(device=device, vocab_size=vocab_size, word_embed=glovemgr.getEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ae1a236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN_RNN(\n",
       "  (word_embedding): Embedding(150002, 100)\n",
       "  (word_GRU): GRU(100, 200, batch_first=True, bidirectional=True)\n",
       "  (sent_GRU): GRU(400, 200, batch_first=True, bidirectional=True)\n",
       "  (rel_pos_emb): Embedding(11, 100)\n",
       "  (abs_pos_emb): Embedding(100, 100)\n",
       "  (Wdoc): Linear(in_features=400, out_features=400, bias=True)\n",
       "  (Wcontent): Linear(in_features=400, out_features=1, bias=False)\n",
       "  (Wsalience): Bilinear(in1_features=400, in2_features=400, out_features=1, bias=False)\n",
       "  (Wnovelty): Bilinear(in1_features=400, in2_features=400, out_features=1, bias=False)\n",
       "  (Wabs_pos): Linear(in_features=100, out_features=1, bias=False)\n",
       "  (Wrel_pos): Linear(in_features=100, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bc411ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "mae_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c803c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./checkpoints\"):\n",
    "    os.makedirs(\"./checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0991d3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6062/6062 [1:46:08<00:00,  1.05s/batch, accuracy=0.813, loss=0.366, mae=0.221]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 : train loss = 0.366, val loss = 0.354, train mae = 0.221, val mae = 0.216, train accuracy = 0.813, val accuracy = 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 6062/6062 [1:46:51<00:00,  1.06s/batch, accuracy=0.816, loss=0.359, mae=0.217]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 : train loss = 0.359, val loss = 0.352, train mae = 0.217, val mae = 0.213, train accuracy = 0.816, val accuracy = 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 6062/6062 [1:46:40<00:00,  1.06s/batch, accuracy=0.818, loss=0.355, mae=0.215]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 : train loss = 0.355, val loss = 0.352, train mae = 0.215, val mae = 0.212, train accuracy = 0.818, val accuracy = 0.820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 6062/6062 [1:47:36<00:00,  1.07s/batch, accuracy=0.82, loss=0.351, mae=0.213]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 : train loss = 0.351, val loss = 0.353, train mae = 0.213, val mae = 0.211, train accuracy = 0.820, val accuracy = 0.819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 6062/6062 [1:47:38<00:00,  1.07s/batch, accuracy=0.823, loss=0.346, mae=0.21]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 : train loss = 0.346, val loss = 0.358, train mae = 0.210, val mae = 0.209, train accuracy = 0.823, val accuracy = 0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 6062/6062 [1:47:01<00:00,  1.06s/batch, accuracy=0.826, loss=0.341, mae=0.207]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 : train loss = 0.341, val loss = 0.364, train mae = 0.207, val mae = 0.207, train accuracy = 0.826, val accuracy = 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 6062/6062 [1:48:47<00:00,  1.08s/batch, accuracy=0.83, loss=0.335, mae=0.204]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 : train loss = 0.335, val loss = 0.368, train mae = 0.204, val mae = 0.204, train accuracy = 0.830, val accuracy = 0.814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 6062/6062 [1:44:20<00:00,  1.03s/batch, accuracy=0.833, loss=0.329, mae=0.2]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 : train loss = 0.329, val loss = 0.375, train mae = 0.200, val mae = 0.200, train accuracy = 0.833, val accuracy = 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 6062/6062 [1:44:08<00:00,  1.03s/batch, accuracy=0.836, loss=0.325, mae=0.198]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 : train loss = 0.325, val loss = 0.378, train mae = 0.198, val mae = 0.202, train accuracy = 0.836, val accuracy = 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 6062/6062 [1:43:58<00:00,  1.03s/batch, accuracy=0.838, loss=0.32, mae=0.195]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : train loss = 0.320, val loss = 0.377, train mae = 0.195, val mae = 0.205, train accuracy = 0.838, val accuracy = 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 6062/6062 [1:44:09<00:00,  1.03s/batch, accuracy=0.841, loss=0.316, mae=0.192] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 : train loss = 0.316, val loss = 0.384, train mae = 0.192, val mae = 0.203, train accuracy = 0.841, val accuracy = 0.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 6062/6062 [1:44:04<00:00,  1.03s/batch, accuracy=0.843, loss=0.312, mae=0.19]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 : train loss = 0.312, val loss = 0.378, train mae = 0.190, val mae = 0.208, train accuracy = 0.843, val accuracy = 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 6062/6062 [1:45:07<00:00,  1.04s/batch, accuracy=0.845, loss=0.309, mae=0.188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 : train loss = 0.309, val loss = 0.389, train mae = 0.188, val mae = 0.209, train accuracy = 0.845, val accuracy = 0.807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14:  69%|██████▉   | 4205/6062 [1:13:41<32:32,  1.05s/batch, accuracy=0.846, loss=0.306, mae=0.186]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb Cellule 14\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m targets \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m probs \u001b[39m=\u001b[39m model(features, doc_lens)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_fn(probs, targets)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb Cellule 14\u001b[0m in \u001b[0;36mRNN_RNN.forward\u001b[0;34m(self, arr_x, doc_lens)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m arr_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_embedding(arr_x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m arr_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mword_GRU(arr_x)[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m arr_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mavg_pool1d(arr_x, sent_lens)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m arr_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_doc(arr_x, doc_lens)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m arr_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msent_GRU(arr_x)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;32m/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb Cellule 14\u001b[0m in \u001b[0;36mRNN_RNN.avg_pool1d\u001b[0;34m(self, x, seq_lens)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m out \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m index,t \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     \u001b[39mif\u001b[39;00m seq_lens[index] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m         t \u001b[39m=\u001b[39m t[:\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/rsaid/stage/code/SummaRuNNer/train_RNN_RNN.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "for epoch in range(1, epochs+1):\n",
    "    # train 1 epoch\n",
    "    model.train()\n",
    "    nb_batch_train = 0\n",
    "    total_train_loss = 0\n",
    "    total_train_mae = 0\n",
    "    total_train_acc = 0\n",
    "    with tqdm(train_iter, unit=\"batch\", total=len(train_iter)) as tepoch:\n",
    "        for batch in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            features = []\n",
    "            doc_lens = []\n",
    "\n",
    "            for j in range(batch_size):\n",
    "                doc_lens.append(len(batch[j][\"doc\"]))\n",
    "                features = features + batch[j][\"doc\"]\n",
    "            \n",
    "            features = torch.tensor(features, dtype=torch.long).to(device)\n",
    "\n",
    "            targets = [torch.tensor(batch[j][\"labels\"], dtype=torch.float) for j in range(batch_size)]\n",
    "            targets = torch.cat(targets)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            probs = model(features, doc_lens)\n",
    "            \n",
    "            loss = loss_fn(probs, targets)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            nb_batch_train += 1\n",
    "            total_train_loss += loss.item()\n",
    "            total_train_mae += mae_fn(probs, targets).item()\n",
    "            total_train_acc += accuracy_prop_sent_per_doc_fn(probs=probs.cpu().detach().numpy(), targets=targets.cpu().detach().numpy(), doc_lens=doc_lens)\n",
    "            tepoch.set_postfix(loss=total_train_loss/nb_batch_train, mae=total_train_mae/nb_batch_train, accuracy=total_train_acc/nb_batch_train)\n",
    "    # Save model\n",
    "    model.save(\"./checkpoints/RNN_RNN-\" + str(epoch) + \".pt\")\n",
    "    # Show train and val score\n",
    "    model.eval()\n",
    "    nb_batch_val = 0\n",
    "    total_val_loss = 0\n",
    "    total_val_mae = 0\n",
    "    total_val_acc = 0\n",
    "    for i,batch in enumerate(val_iter):\n",
    "        features = []\n",
    "        doc_lens = []\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            doc_lens.append(len(batch[j][\"doc\"]))\n",
    "            features = features + batch[j][\"doc\"]\n",
    "            \n",
    "        features = torch.tensor(features, dtype=torch.long).to(device)\n",
    "\n",
    "        targets = [torch.tensor(batch[j][\"labels\"], dtype=torch.float) for j in range(batch_size)]\n",
    "        targets = torch.cat(targets)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        probs = model(features, doc_lens)\n",
    "        loss = loss_fn(probs, targets)\n",
    "        nb_batch_val += 1\n",
    "        total_val_loss += loss.item()\n",
    "        total_val_mae += mae_fn(probs, targets).item()\n",
    "        total_val_acc += accuracy_prop_sent_per_doc_fn(probs=probs.cpu().detach().numpy(), targets=targets.cpu().detach().numpy(), doc_lens=doc_lens)\n",
    "    print(\"Epoch {} : train loss = {:.3f}, val loss = {:.3f}, train mae = {:.3f}, val mae = {:.3f}, train accuracy = {:.3f}, val accuracy = {:.3f}\".format(epoch, total_train_loss / nb_batch_train, total_val_loss / nb_batch_val, total_train_mae / nb_batch_train, total_val_mae / nb_batch_val, total_train_acc / nb_batch_train, total_val_acc / nb_batch_val))\n",
    "\n",
    "t2 = time()\n",
    "print(\"Training duration =\", t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbae7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_266945/3245586283.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2463\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"doc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vide\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/stage/code/SummaRuNNer/utils/DataLoader.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlidx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlidx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Bureau/stage/code/SummaRuNNer/utils/Dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tmp = train_iter.__getitem__(2463)[0][\"doc\"]\n",
    "for e in tmp:\n",
    "  if (e[0] == 0):\n",
    "    print(\"vide\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e602c7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6d7f428a150b92572ac46240b6d7ae68586908362b054f21341550673eeb77dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
